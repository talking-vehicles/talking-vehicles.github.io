<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Talking Vehicles: Towards Natural Language Communication for Cooperative Autonomous Driving via Self-Play">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Talking Vehicles: Towards Natural Language Communication for Cooperative Autonomous Driving via Self-Play</title>

  <!-- TODO: Global site tag (gtag.js) - Google Analytics -->

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Talking Vehicles: Towards Natural Language Communication for Cooperative Autonomous Driving via Self-Play</h1>
          <div class="is-size-5 publication-authors">
      <span class="author-block">
      <a href="https://cuijiaxun.github.io/">Jiaxun Cui</a><sup>1</sup></a>,
      <a href="https://chentangmark.github.io/">Chen Tang</a><sup>1</sup>,
      Jarrett Holtz<sup>2</sup>,
      Janice Nguyen<sup>3</sup>,
      <a href="https://scholar.google.co.uk/citations?user=T5JSHMoAAAAJ&hl=en">Alessandro G. Allievi</a><sup>2</sup>,
      <a href="https://hangqiu.github.io/">Hang Qiu</a><sup>3</sup>,
      <a href="https://www.cs.utexas.edu/~pstone/">Peter Stone</a><sup>1,4</sup>
      </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>The University of Texas at Austin</span>,
            <span class="author-block"><sup>2</sup>Robert Bosch LLC</span>,
            <span class="author-block"><sup>3</sup>University of California, Riverside</span>,
            <span class="author-block"><sup>4</sup>Sony AI</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="./static/pdf/Talking_Vehicles__CoRL_2025_Arxiv.pdf"
                  target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <!-- Arxiv Link. -->
              <span class="link-block">
                <a href="http://arxiv.org/abs/2401.12963"
                  target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/cuijiaxun/talking-vehicles"
                  target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                </a>
              </span>
              <!-- Demo Link. -->
              <span class="link-block">
                <a href="https://utexas.box.com/s/5pn2rfcprqv9p992m9lzyeaurq8irrhd"
                  target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-play"></i>
                  </span>
                  <span>Demo</span>
                </a>
              </span>
              <!-- BibTex Link. -->
              <span class="link-block">
                <a href="#BibTeX"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-book-open"></i>
                  </span>
                  <span>BibTex</span>
                </a>
              </span>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Past work has demonstrated that autonomous vehicles can drive more safely if they communicate with one another than if they do not. 
            However, their communication has often not been human-understandable. Using natural language as a vehicle-to-vehicle (V2V) 
            communication protocol offers the potential for autonomous vehicles to drive cooperatively not only with each other but also with 
            human drivers. In this work, we propose a suite of traffic tasks in autonomous driving where vehicles in a traffic scenario need 
            to communicate in natural language to facilitate coordination in order to avoid an imminent collision and/or support efficient 
            traffic flow. To this end, this paper introduces a novel method, LLM+Debrief, to learn a message generation and high-level decision-making 
            policy for autonomous vehicles through multi-agent discussion. To evaluate LLM agents for driving, we developed a gym-like simulation 
            environment that contains a range of driving scenarios. Our experimental results demonstrate that LLM+Debrief is more effective at 
            generating meaningful and human-understandable natural language messages to facilitate cooperation and coordination than a zero-shot 
            LLM agent. 
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
  </div>
</section>

<!--Talking Vehicles Gym Environment-->
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">TalkingVehiclesGym</h2>
        <div class="content has-text-justified">
          <p>
            TalkingVehiclesGym is a multi-agent gymnasium simulation environment for the closed-loop evaluation of urban driving policies. 
            It is designed to evaluate the performance of multi-agent communication and collaboration for an array of cooperative driving tasks. 
            TalkingVehiclesGym supports in-episode communication in among autonomous agents through <a href="https://mqtt.org/">MQTT</a>.
          </p>
          <p>
            <img style="max-width:100%" src="./static/images/talking_vehicle_scenarios.png" class="img-reponsive" />
            <figcaption class="has-text-centered has-text-grey-dark is-size-8">
              <b>Overview of Scenarios and Agent Roles.</b>
              <span style="color: #006400;" class="has-text-weight-bold">Green circles</span>: Focal agents (establish coordination through communication); 
              <span style="color: #8B0000;" class="has-text-weight-bold">Red circles</span>: Potential colliders (violate traffic rules or do not yield); 
              <span style="color: #00008B;" class="has-text-weight-bold">Blue circles</span>: Background agents (not necessarily adversarial).
            </figcaption>
          </p>
        </div>
      </div>
    </div>
</section>

<!--LLM+Debrief Method-->
<section class="section">
  <div class="container is-max-desktop">
    <!-- Overview -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">
          LLM+Debrief
          <span class="is-size-4" style="color: #666666;">Learn to Collaborate in Natural Language via Self-Play</span>
        </h2>
        <p>
          We ask the key research question that whether the current LLM agents are able to coordination well in the driving task without pre-coordination,
          and whether their cooperation capability could be improved over interactions. We start from building an agent that only rely on Chain-of-Thought,
          gradually extending to self-reflections and centralized discussions (LLM+Debrief) to create knowledge for future driving and collaborations.
        </p>
        <br>
        <div class="content has-text-justified">
          <p style="text-align:center;">
            <img style="max-width:100%" src="./static/images/llm_debrief_method.png" class="img-reponsive" />
            <figcaption class="has-text-centered has-text-grey-dark is-size-8">
              <b>LLM+Debrief Agent Framework and Agent Learning Pipeline.</b>
            </figcaption>
          </p>
        </div>
        <div class="content has-text-justified">
          <p class="has-text-weight-bold is-size-4 has-text-grey-dark">Agent Policy</p>
            <p>
              The agent's probability distribution among actions is decided by an LLM with a prompt that contains the observations, tasks, traffic rules,
              received messages from other vehicles, and other important information for driving. The agent output must be in the json format that decides 
              a command and/or a message to send.
            </p>
          <ol>
            <li>
              <strong>In-Context Knowledge</strong>
              <p>
                Since the language models are auto-regressive, the probability of taking action is affected by the context provided to the agents.
                Thus, we can augment the prompt with the prior knowledge to alter the policy.
              </p>
            </li>
            <li>
              <strong>Chain-of-Thought Reasoning</strong>
              <p>
                We prompt the agent to reason about its surrounding and possible consequence of each action first, then then serve the output reasoning 
                as a part of the prompt for final decisions.
              </p>
            </li>
          </ol>
        
          <p class="has-text-weight-bold is-size-4 has-text-grey-dark">Agent Learning</p>
          <ol>
            <li><strong>Replay Buffer</strong></li>
            <li><strong>Batch Sampling</strong></li>
            <li><strong>Debrief</strong></li>
          </ol>
        </div>
      </div>
    </div>
  </div>
</section>

<!--Experiments-->
<section class="section">
  <div class="container is-max-desktop content">
    <h2 class="title is-3">Experiments</h2>
    <p>
      Talking Vehicles is a promising step towards AI agents that can purposefully communicate with each other 
      and humans in a natural language to coordinate on a task via self-play among agents. Future work will be
      directed towards creating more robust and diverse learned policies, integrating larger multimodal models,
      and studying the learning methods that can train the agents to perform more complex tasks.
    </p>
  </div>
</section>

<!-- Qualitative Videos -->
<section class="section" id="QualitativeVideos">
  <div class="container is-max-desktop content">
    <h2 class="title is-3">Qualitative Videos</h2>
    
    <!-- Row 1 -->
    <div class="columns">
      <div class="column">
        <h4 class="subtitle is-5" style="color: #666666;">Scenario 1: Perception Overtake</h4>
        <video controls style="width:100%; height:auto; border:1px solid #ddd;">
          <source src="./static/videos/perception_overtake_risky_distill_success.mp4" type="video/mp4">
          Your browser does not support the video tag.
        </video>
      </div>
      <div class="column">
        <h4 class="subtitle is-5" style="color: #666666;">Scenario 2: Perception Red Light</h4>
        <video controls style="width:100%; height:auto; border:1px solid #ddd;">
          <source src="./static/videos/perception_red_light_risky_distill_success.mp4" type="video/mp4">
          Your browser does not support the video tag.
        </video>
      </div>
    </div>

    <!-- Row 2 -->
    <div class="columns">
      <div class="column">
        <h4 class="subtitle is-5" style="color: #666666;">Scenario 3: Perception Left Turn</h4>
        <video controls style="width:100%; height:auto; border:1px solid #ddd;">
          <source src="./static/videos/perception_left_turn_risky_debrief_success.mp4" type="video/mp4">
          Your browser does not support the video tag.
        </video>
      </div>
      <div class="column">
        <h4 class="subtitle is-5" style="color: #666666;">Scenario 4: Negotiation Overtake</h4>
        <video controls style="width:100%; height:auto; border:1px solid #ddd;">
          <source src="./static/videos/negotiation_overtake_risky_distill_success.mp4" type="video/mp4">
          Your browser does not support the video tag.
        </video>
      </div>
    </div>

    <!-- Row 3 -->
    <div class="columns">
      <div class="column">
        <h4 class="subtitle is-5" style="color: #666666;">Scenario 5: Negotiation Highway Merge</h4>
        <video controls style="width:100%; height:auto; border:1px solid #ddd;">
          <source src="./static/videos/negotiation_highway_merge_risky_distill_success.mp4" type="video/mp4">
          Your browser does not support the video tag.
        </video>
      </div>
      <div class="column">
        <h4 class="subtitle is-5" style="color: #666666;">Scenario 6: Negotiation Highway Exit</h4>
        <video controls style="width:100%; height:auto; border:1px solid #ddd;">
          <source src="./static/videos/negotiation_highway_exit_risky_distill_success.mp4" type="video/mp4">
          Your browser does not support the video tag.
        </video>
      </div>
    </div>

  </div>
</section>

<!--Example Knowledges-->

<!--Distillation-->

<section class="section">
  <div class="container is-max-desktop content">
    <h2 class="title is-3">Future Work</h2>
    <p>
      Talking Vehicles is a promising step towards AI agents that can purposefully communicate with each other 
      and humans in a natural language to coordinate on a task via self-play among agents. Future work will be
      directed towards creating more robust and diverse learned policies, integrating larger multimodal models,
      and studying the learning methods that can train the agents to perform more complex tasks.
    </p>
  </div>
</section>

<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{cui2025talking,
      title={Talking Vehicles: Towards Natural Language Communication for Cooperative Autonomous Driving via Self-Play}, 
      author={Jiaxun Cui and Chen Tang and Jarrett Holtz and Janice Nguyen and Alessandro G. Allievi and Hang Qiu and Peter Stone},
      year={2025},
      eprint={TODO},
      archivePrefix={arXiv},
      primaryClass={TODO}
}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         target="_blank"
         href="./static/pdf/Talking_Vehicles__CoRL_2025_Arxiv.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>This website is borrowed from <a href="https://nerfies.github.io/">nerfies</a>.</p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
