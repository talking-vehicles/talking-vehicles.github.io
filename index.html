<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Talking Vehicles: Towards Natural Language Communication for Cooperative Autonomous Driving via Self-Play">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Talking Vehicles: Towards Natural Language Communication for Cooperative Autonomous Driving via Self-Play</title>

  <!-- TODO: Global site tag (gtag.js) - Google Analytics -->

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Talking Vehicles: Towards Natural Language Communication for Cooperative Autonomous Driving via Self-Play</h1>
          <div class="is-size-5 publication-authors">
      <span class="author-block">
      <a href="https://cuijiaxun.github.io/">Jiaxun Cui</a><sup>1</sup></a>,
      <a href="https://chentangmark.github.io/">Chen Tang</a><sup>1</sup>,
      <a href="https://scholar.google.com/citations?user=_XUgxrcAAAAJ&hl=en">Jarrett Holtz</a><sup>2</sup>,
      <a href="https://scholar.google.com/citations?user=lHO7zwwAAAAJ&hl=en">Janice Nguyen</a><sup>3</sup>,
      <a href="https://scholar.google.co.uk/citations?user=T5JSHMoAAAAJ&hl=en">Alessandro G. Allievi</a><sup>2</sup>,
      <a href="https://hangqiu.github.io/">Hang Qiu</a><sup>3</sup>,
      <a href="https://www.cs.utexas.edu/~pstone/">Peter Stone</a><sup>1,4</sup>
      </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>The University of Texas at Austin</span>,
            <span class="author-block"><sup>2</sup>Robert Bosch LLC</span>,
            <span class="author-block"><sup>3</sup>University of California, Riverside</span>,
            <span class="author-block"><sup>4</sup>Sony AI</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="./static/pdf/Talking_Vehicles__CoRL_2025_Arxiv.pdf"
                  target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <!-- Arxiv Link. -->
              <span class="link-block">
                <a href="http://arxiv.org/abs/2401.12963"
                  target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/cuijiaxun/talking-vehicles"
                  target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                </a>
              </span>
              <!-- Demo Link. -->
              <span class="link-block">
                <a href="https://utexas.box.com/s/5pn2rfcprqv9p992m9lzyeaurq8irrhd"
                  target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-play"></i>
                  </span>
                  <span>Demo</span>
                </a>
              </span>
              <!-- BibTex Link. -->
              <span class="link-block">
                <a href="#BibTeX"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-book-open"></i>
                  </span>
                  <span>BibTex</span>
                </a>
              </span>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Past work has demonstrated that autonomous vehicles can drive more safely if they communicate with one another than if they do not. 
            However, their communication has often not been human-understandable. Using natural language as a vehicle-to-vehicle (V2V) 
            communication protocol offers the potential for autonomous vehicles to drive cooperatively not only with each other but also with 
            human drivers. In this work, we propose a suite of traffic tasks in autonomous driving where vehicles in a traffic scenario need 
            to communicate in natural language to facilitate coordination in order to avoid an imminent collision and/or support efficient 
            traffic flow. To this end, this paper introduces a novel method, LLM+Debrief, to learn a message generation and high-level decision-making 
            policy for autonomous vehicles through multi-agent discussion. To evaluate LLM agents for driving, we developed a gym-like simulation 
            environment that contains a range of driving scenarios. Our experimental results demonstrate that LLM+Debrief is more effective at 
            generating meaningful and human-understandable natural language messages to facilitate cooperation and coordination than a zero-shot 
            LLM agent. 
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
  </div>
</section>

<!--Talking Vehicles Gym Environment-->
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">TalkingVehiclesGym</h2>
        <div class="content has-text-justified">
          <p>
            TalkingVehiclesGym is a multi-agent gymnasium simulation environment for the closed-loop evaluation of urban driving policies. 
            It is designed to evaluate the performance of multi-agent communication and collaboration for an array of cooperative driving tasks. 
            TalkingVehiclesGym supports in-episode communication in among autonomous agents through <a href="https://mqtt.org/">MQTT</a>.
          </p>
          <p>
            <img style="max-width:100%" src="./static/images/talking_vehicle_scenarios.png" class="img-reponsive" />
            <figcaption class="has-text-centered has-text-grey-dark is-size-8">
              <b><strong>Figure 1.</strong>Overview of Scenarios and Agent Roles.</b>
              <span style="color: #006400;" class="has-text-weight-bold">Green circles</span>: Focal agents (establish coordination through communication); 
              <span style="color: #8B0000;" class="has-text-weight-bold">Red circles</span>: Potential colliders (violate traffic rules or do not yield); 
              <span style="color: #00008B;" class="has-text-weight-bold">Blue circles</span>: Background agents (not necessarily adversarial).
            </figcaption>
          </p>
        </div>
      </div>
    </div>
</section>

<!--LLM+Debrief Method-->
<section class="section">
  <div class="container is-max-desktop">
    <!-- Overview -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">
          LLM+Debrief
          <span class="is-size-4" style="color: #666666;">Learn to Collaborate using Natural Language via Self-Play</span>
        </h2>
        <p>
          We ask the key research question that whether the current LLM agents are able to coordination well in the driving task without pre-coordination,
          and whether their cooperation capability could be improved over interactions. We start from building an agent that only rely on Chain-of-Thought,
          gradually extending to self-reflections and centralized discussions (LLM+Debrief) to create knowledge for future driving and collaborations.
        </p>
        <br>
        <div class="content has-text-justified">
          <p style="text-align:center;">
            <img style="max-width:100%" src="./static/images/llm_debrief_method.png" class="img-reponsive" />
            <figcaption class="has-text-centered has-text-grey-dark is-size-8">
              <b><strong>Figure 2.</strong>LLM+Debrief Agent Framework and Agent Learning Pipeline.</b>
            </figcaption>
          </p>
        </div>
        <div class="content has-text-justified">
          <p class="has-text-weight-bold is-size-4 has-text-grey-dark">Agent Policy</p>
            <p>
              The agent's probability distribution among actions is decided by an LLM with a prompt that contains the observations, tasks, traffic rules,
              received messages from other vehicles, and other important information for driving. The agent output must be in the json format that decides 
              a command and/or a message to send.
            </p>
          <ol>
            <li>
              <strong>In-Context Knowledge</strong>
              <p>
                Since the language models are auto-regressive, the probability of taking action is affected by the context provided to the agents.
                Thus, we can augment the prompt with the prior knowledge to alter the policy.
              </p>
            </li>
            <li>
              <strong>Chain-of-Thought Reasoning</strong>
              <p>
                We prompt the agent to reason about its surrounding and possible consequence of each action first, then then serve the output reasoning 
                as a part of the prompt for final decisions.
              </p>
            </li>
          </ol>
        
          <p class="has-text-weight-bold is-size-4 has-text-grey-dark">Agent Learning</p>
            <p>
              Initially, the LLM agents interact with each other in the scenarios and store their experience in the relay buffer. The agents then
              enage in a discussion session where they sample past experience as a context to refine their joint cooperative strategy.
            </p>
          <ol>
            <li>
              <strong>Replay Buffer</strong>
                <p>
                  We store the transition data (observations, actions, next observations) in a replay buffer. When an episode concludes, the environment will
                  each agent's performance and provide scalar rewards, as well as verbal feedbacks like "Vehicle 109 collided with Vehicle 110 after 2 seconds"
                  or "Vehicle 111 stagnated for too long to complete its task." Each transition data is retrospectively labeled with enriched meta data, including 
                  responses from other agents, collision details, stagnaition specifics and final outcomes.
                </p>
            </li>
            <li>
              <strong>Batch Sampling</strong>
              <p>
                While analyzing the entire trajectory would provide
                a comprehensive understanding of failure cases, computational constraints necessitate sampling a
                subset (batch) of keyframes from its replay buffer. To prioritize relevant data, the sampling process
                heuristically assigns higher probabilities to transitions that occur immediately
                before collisions, involve actions contributing to collisions, or lead to stagnation due to agents slowing
                down. Additionally, transitions that feature more intensive multi-agent interactions are given more
                weight.
              </p>
            </li>
            <li>
              <strong>Debrief</strong>
              <p>
                A debriefing session begins when an episode concludes in failure (collision or stagnation) 
                and is conducted in a turn-based manner over N rounds, with a focus on improving cooperation
                in future interactions. The speaking order is deterministic in this work for each session, and agents
                take turns speaking in a round-robin format. The agent chosen to speak first is responsible for
                proposing a joint cooperative strategy for everyone participating in the debriefing
                (the focal group). This agent begins by reasoning through its transition data batch, analyzing the
                consequences and influence on other agents of its actions, and formulating a proposed strategy.
                Subsequently, the other agents take turns sharing their perspectives, providing feedback, or offering
                alternative insights based on their analysis of their own experience batch. After the discussion, each
                agent summarizes the discussion to develop individual cooperative strategies and knowledge. 
                These outcomes serve as in-context guidelines for future driving tasks. This joint discussion
                for future individual decision-making structure mirrors the principles of the Centralized Training
                Decentralized Execution (CTDE) framework.
              </p>
            </li>
          </ol>
        </div>
      </div>
    </div>
  </div>
</section>

<!--Experiments-->
<section class="section">
  <div class="container is-max-desktop content">
    <h2 class="title is-3">Experiments</h2>
    <p>We established several baselines and scenarios to answer the research questions:</p>
    <ul>
      <li>
        <strong>Zero-shot</strong>: an LLM agent using Chain-of-Thought (CoT) reasoning only.
      </li>
      <li>
        <strong>Reflection</strong>: an LLM agent with CoT reasoning contextualized with knowledge from decentralized reflection.
      </li>
      <li>
        <strong>Correction+RAG</strong>: an LLM agent that corrects past actions via self-reflection, 
        stores these corrections in a vector-based retrievable memory, and uses few-shot retrieved-example augmented generation.
      </li>
      <li>
        <strong>Correction+RAG (Silent)</strong>: the retrieval-augmented method without communication (adapting <a href="https://pjlab-adg.github.io/DiLu/">DiLU</a>, 
        a non-communicating single-agent LLM-based reflection-driving approach, to our environment).
      </li>
      <li>
        <strong>Correction+RAG (Comm)</strong>: the multi-agent communication extension of DiLU (<a href="https://arxiv.org/abs/2404.06345">AgentsCoDriver</a>), 
        which resembles Correction+RAG but does not actively optimize the messages.
      </li>
    </ul>
    <p>
      For a fair comparison across these LLM-based baselines, we did not initialize any knowledge with human data, nor was there human involvement during the learning process.
    </p>
    <figure class="image is-full-width" style="margin-top: 2em;">
      <img src="./static/images/talking_vehicle_quantative_results.png" alt="Quantitative results for the talking vehicles experiments">
      <figcaption class="has-text-centered">
        <strong>Figure 3.</strong> Quantitative performance comparison across baselines: Zero-shot, Reflection, Correction+RAG, and their Communication/Silent variants.
      </figcaption>
    </figure>
  </div>
</section>


<!-- Qualitative Videos -->
<section class="section" id="QualitativeVideos">
  <div class="container is-max-desktop content">
    <h2 class="title is-3">Qualitative Videos</h2>
    
    <!-- Row 1 -->
    <div class="columns">
      <div class="column">
        <h4 class="subtitle is-5" style="color: #666666;">Scenario 1: Perception Overtake</h4>
        <video controls style="width:100%; height:auto; border:1px solid #ddd;">
          <source src="./static/videos/perception_overtake_risky_distill_success.mp4" type="video/mp4">
          Your browser does not support the video tag.
        </video>
      </div>
      <div class="column">
        <h4 class="subtitle is-5" style="color: #666666;">Scenario 2: Perception Red Light</h4>
        <video controls style="width:100%; height:auto; border:1px solid #ddd;">
          <source src="./static/videos/perception_red_light_risky_distill_success.mp4" type="video/mp4">
          Your browser does not support the video tag.
        </video>
      </div>
    </div>

    <!-- Row 2 -->
    <div class="columns">
      <div class="column">
        <h4 class="subtitle is-5" style="color: #666666;">Scenario 3: Perception Left Turn</h4>
        <video controls style="width:100%; height:auto; border:1px solid #ddd;">
          <source src="./static/videos/perception_left_turn_risky_debrief_success.mp4" type="video/mp4">
          Your browser does not support the video tag.
        </video>
      </div>
      <div class="column">
        <h4 class="subtitle is-5" style="color: #666666;">Scenario 4: Negotiation Overtake</h4>
        <video controls style="width:100%; height:auto; border:1px solid #ddd;">
          <source src="./static/videos/negotiation_overtake_risky_distill_success.mp4" type="video/mp4">
          Your browser does not support the video tag.
        </video>
      </div>
    </div>

    <!-- Row 3 -->
    <div class="columns">
      <div class="column">
        <h4 class="subtitle is-5" style="color: #666666;">Scenario 5: Negotiation Highway Merge</h4>
        <video controls style="width:100%; height:auto; border:1px solid #ddd;">
          <source src="./static/videos/negotiation_highway_merge_risky_distill_success.mp4" type="video/mp4">
          Your browser does not support the video tag.
        </video>
      </div>
      <div class="column">
        <h4 class="subtitle is-5" style="color: #666666;">Scenario 6: Negotiation Highway Exit</h4>
        <video controls style="width:100%; height:auto; border:1px solid #ddd;">
          <source src="./static/videos/negotiation_highway_exit_risky_distill_success.mp4" type="video/mp4">
          Your browser does not support the video tag.
        </video>
      </div>
    </div>

  </div>
</section>

<!-- Example Learned Knowledge -->
<section class="section" id="example-learned-knowledge">
  <div class="container is-max-desktop content">
    <h2 class="title is-3">Example Learned Knowledge</h2>

    <!-- Tabs navigation -->
    <div class="tabs is-toggle" id="scenario-tabs">
      <ul>
        <li class="is-active" data-tab="perception-overtake"><a>Perception Overtake</a></li>
        <li data-tab="perception-red-light"><a>Perception Red Light</a></li>
        <li data-tab="perception-left-turn"><a>Perception Left Turn</a></li>
        <li data-tab="negotiation-overtake"><a>Negotiation Overtake</a></li>
        <li data-tab="negotiation-highway-merge"><a>Negotiation Hwy Merge</a></li>
        <li data-tab="negotiation-highway-exit"><a>Negotiation Hwy Exit</a></li>
      </ul>
    </div>

    <!-- Content panes -->
    <div>
      <div id="perception-overtake" class="tab-content">
        <h3 class="title is-4">Perception Overtake</h3>
        <video controls style="width:100%; height:auto; border:1px solid #ddd;">
          <source src="./static/videos/perception_overtake_risky_distill_success.mp4" type="video/mp4">
          Your browser does not support the video tag.
        </video>
        <p><strong>Car1 (Overtaking), Vehicle 197</strong></p>
        <div class="content has-text-justified">
          <p>
            In our refined cooperative strategy, the stationary vehicle in lane 1 will continuously monitor lane -1 
            for any approaching traffic and provide real-time alerts. Meanwhile, the overtaking vehicle will actively 
            use its sensors to independently verify the status of lane -1. If both the stationary vehicle's observations 
            and the overtaking vehicle's sensors confirm that lane -1 is clear, the overtaking vehicle will promptly 
            proceed with the maneuver to avoid stagnation. If the stationary vehicle detects any traffic in lane -1, 
            it will immediately communicate this, advising the overtaking vehicle to hold its position. The overtaking 
            vehicle will remain ready to accelerate smoothly once the lane is confirmed clear. This dual-verification approach, 
            combining sensor data and real-time communication, ensures a timely and safe overtaking maneuver, 
            preventing collisions and minimizing stagnation.
          </p>
        </div>
        <p><strong>Truck (Stopped Truck in Lane 1), Vehicle 199</strong></p>
        <div class="content has-text-justified">
          <p>
            In our refined cooperative strategy, as the stationary truck in lane 1, I will continuously monitor lane -1 
            for any approaching traffic and provide immediate alerts if I detect any vehicles, advising the overtaking 
            vehicle to hold its position. Meanwhile, the overtaking vehicle will actively use its sensors to independently 
            verify the status of lane -1. If both my observations and the overtaking vehicle's sensors confirm that lane -1 
            is clear, the overtaking vehicle should promptly proceed with the overtaking maneuver to avoid stagnation. This 
            dual-verification approach, combining sensor data and real-time alerts, ensures a timely and safe overtaking 
            maneuver, preventing collisions and minimizing stagnation.
          </p>
        </div>
      </div>
      <div id="perception-red-light" class="tab-content is-hidden">
        <h3 class="title is-4">Perception Red Light</h3>
        <video controls style="width:100%; height:auto; border:1px solid #ddd;">
          <source src="./static/videos/perception_red_light_risky_distill_success.mp4" type="video/mp4">
          Your browser does not support the video tag.
        </video>
        <p><strong>Car1 (Proceeding Forward with Green Lights), Vehicle 109</strong></p>
        <div class="content has-text-justified"> 
          <p>
            In our cooperative strategy, the vehicle with the best view of the intersection, typically positioned to turn 
            left, will lead in monitoring and communicating updates about potential threats. This vehicle will provide 
            real-time information about any approaching vehicles against a red light, including their distance and speed, 
            and confirm when they have stopped or are no longer a threat. If a threat is detected, the vehicle with the 
            green light, ready to proceed straight through the intersection, should remain stationary until the intersection 
            is confirmed clear. The monitoring vehicle will send updates every few seconds to keep all vehicles informed. 
            Once the threat is resolved, the monitoring vehicle will confirm the intersection is clear, allowing the vehicle 
            with the green light to proceed promptly and safely. This plan ensures safety by preventing collisions and minimizes 
            unnecessary delays by enabling vehicles to pass through the intersection efficiently when it is safe to do so.
          </p>
        </div>
        <p><strong>Truck (Stopped at Intersection), Vehicle 117</strong></p>
        <div class="content has-text-justified">
          <p>
            In our cooperative strategy, the vehicle with the best view of the intersection, which is the stationary truck 
            (myself), will lead in monitoring and communicating updates about potential threats. If a vehicle is detected 
            approaching against a red light, I will immediately alert all vehicles, providing specific information about 
            the threat's distance and speed. The vehicle with the green light, positioned to proceed straight through the 
            intersection, should remain stationary until I confirm that the threat has stopped or is no longer present. 
            I will send updates every few seconds to keep all vehicles informed. Once the intersection is clear, I will 
            confirm this, allowing the vehicle with the green light to proceed promptly and safely. This plan ensures safety 
            by preventing collisions and minimizes unnecessary delays by enabling vehicles to pass through the intersection 
            efficiently when it is safe to do so.
          </p>
        </div>
      </div>
      <div id="perception-left-turn" class="tab-content is-hidden">
        <h3 class="title is-4">Perception Left Turn</h3>
        <video controls style="width:100%; height:auto; border:1px solid #ddd;">
          <source src="./static/videos/perception_left_turn_risky_debrief_success.mp4" type="video/mp4">
          Your browser does not support the video tag.
        </video>
        <p><strong>Car1 (Northbound Left Turning), Vehicle 109</strong></p>
        <div class="content has-text-justified">
          <p>
            In our revised cooperative strategy, the stationary vehicle at the intersection will continuously monitor the 
            traffic flow and provide real-time updates to both the left-turning vehicle (myself) and the oncoming vehicle. 
            The stationary vehicle will send a message advising me to slow down and assess the situation, ensuring I only 
            proceed with the left turn when I receive confirmation that the oncoming vehicle has acknowledged the yield 
            instruction. Simultaneously, the stationary vehicle will instruct the oncoming vehicle to yield and adjust its 
            speed to allow me to pass safely. If the oncoming vehicle does not acknowledge or adjust its speed, the stationary 
            vehicle will alert me to stop and wait until it is safe to proceed. This plan ensures that all vehicles are aware 
            of each other's intentions, allowing me to make the left turn safely and efficiently without causing collisions 
            or unnecessary stagnation.
          </p>
        </div>
        <p><strong>Truck (Stopped at Intersection), Vehicle 111</strong></p>
        <div class="content has-text-justified">
          <p>
            In our revised cooperative strategy, as the stationary vehicle with a clear view of the intersection, I will 
            continuously monitor the traffic flow and provide real-time updates to both the northbound left-turning 
            vehicle and the oncoming vehicle. I will send a message to the left-turning vehicle advising it to slow down 
            and assess the situation, ensuring it only proceeds when it receives confirmation that the oncoming vehicle has 
            acknowledged the yield instruction. Simultaneously, I will send a message to the oncoming vehicle instructing 
            it to yield and adjust its speed to allow the left-turning vehicle to pass safely. If the oncoming vehicle does 
            not acknowledge or adjust its speed, I will alert the left-turning vehicle to stop and wait until it is safe to 
            proceed. This plan ensures that all vehicles are aware of each other's intentions, allowing the left-turning 
            vehicle to pass the intersection safely and quickly without causing collisions or unnecessary stagnation.
          </p>
        </div>
      </div>
      <div id="negotiation-overtake" class="tab-content is-hidden">
        <h3 class="title is-4">Negotiation Overtake</h3>
        <video controls style="width:100%; height:auto; border:1px solid #ddd;">
          <source src="./static/videos/negotiation_overtake_risky_distill_success.mp4" type="video/mp4">
          Your browser does not support the video tag.
        </video>
        <p><strong>Car1 (Overtaking Car), Vehicle 197</strong></p>
        <div class="content has-text-justified">
          <p>
            In our cooperative strategy, when I, as the vehicle intending to overtake a stationary truck in my 
            lane, need to move into the opposite lane, I will first send a message to the oncoming vehicle in 
            the opposite lane, indicating my intention to overtake and requesting a temporary speed reduction 
            to create a safe gap. The oncoming vehicle should acknowledge this request and, if feasible, slightly 
            slow down to create a safe gap, but avoid coming to a complete stop to prevent stagnation. Once the 
            gap is sufficient, I will proceed with the overtaking maneuver and return to my original lane as 
            quickly and safely as possible. After completing the maneuver, I will send a confirmation message, 
            allowing the oncoming vehicle to resume its target speed. This plan ensures that I minimize my time 
            in the opposite lane while the other vehicle maintains its urgency, thus preventing collisions and 
            avoiding stagnation. Effective communication and adaptive speed adjustments are key to ensuring both 
            vehicles can complete their tasks safely and efficiently.
          </p>
        </div>
        <p><strong>Car2 (Opposite Car), Vehicle 198</strong></p>
        <div class="content has-text-justified">
          <p>
            In our cooperative strategy, when a vehicle in the opposite lane intends to overtake a stationary 
            vehicle and temporarily move into my lane, it should first send a message indicating its intention 
            and request a temporary speed adjustment. As the vehicle tasked with going forward and keeping lane, 
            I should acknowledge this request and, if feasible, slightly slow down to create a safe gap, 
            but avoid coming to a complete stop to prevent stagnation. The overtaking vehicle should proceed with 
            the maneuver as quickly and safely as possible, minimizing its time in my lane. Once the overtaking 
            vehicle has safely returned to its original lane, it should send a confirmation message, allowing me 
            to resume my target speed. This plan ensures that the overtaking vehicle minimizes its time in the 
            opposite lane while I maintain my urgency, thus preventing collisions and avoiding stagnation. 
            Effective communication and adaptive speed adjustments are key to ensuring both vehicles can 
            complete their tasks safely and efficiently.
          </p>
        </div>
      </div>
      <div id="negotiation-highway-merge" class="tab-content is-hidden">
        <h3 class="title is-4">Negotiation Highway Merge</h3>
        <video controls style="width:100%; height:auto; border:1px solid #ddd;">
          <source src="./static/videos/negotiation_highway_merge_risky_distill_success.mp4" type="video/mp4">
          Your browser does not support the video tag.
        </video>
        <p><strong>Car1 (Merging on to the Highway), Vehicle 120</strong></p>
        <div class="content has-text-justified">
          <p>
            In the cooperative strategy, as the merging vehicle, I will initiate communication by indicating my 
            intention to merge onto the highway and requesting the vehicle directly to my left on the highway 
            to create a gap by slightly slowing down or, if feasible, temporarily changing lanes. The highway 
            vehicle should acknowledge this request and adjust its position accordingly, ensuring it maintains 
            a safe distance. Meanwhile, I will adjust my speed to align with the newly created gap, ensuring I 
            do not accelerate until the highway vehicle has stabilized its speed and distance. The vehicle 
            behind the highway vehicle should maintain its speed or slightly slow down to prevent closing the 
            gap prematurely. Continuous communication will be maintained, with updates on speed adjustments 
            and intentions, to ensure all vehicles are aware of each other's actions. This approach will prevent 
            collisions by ensuring a clear and sufficient gap for merging while avoiding stagnation by coordinating 
            speed and lane adjustments effectively.
          </p>
        </div>
        <p><strong>Car2 (Highway Vehicle), Vehicle 121</strong></p>
        <div class="content has-text-justified">
          <p>
            In the cooperative strategy, the merging vehicle should initiate communication by indicating its 
            intention to merge onto the highway and requesting the highway vehicle directly to its left to create 
            a gap by slightly slowing down. The highway vehicle, which is myself, should acknowledge this request 
            and slightly reduce speed to create a safe merging space, while maintaining my lane and preparing to 
            accelerate once the merge is complete. The merging vehicle should adjust its speed to align with the 
            gap, ensuring it does not accelerate until I have stabilized my speed and distance. The vehicle behind 
            me on the highway should maintain its speed or slightly slow down to prevent closing the gap prematurely. 
            Continuous communication should be maintained, with updates on speed adjustments and intentions, to 
            ensure all vehicles are aware of each other's actions. This approach will prevent collisions by ensuring 
            a clear and sufficient gap for merging while avoiding stagnation by coordinating speed adjustments effectively.
          </p>
        </div>
      </div>
      <div id="negotiation-highway-exit" class="tab-content is-hidden">
        <h3 class="title is-4">Negotiation Highway Exit</h3>
        <video controls style="width:100%; height:auto; border:1px solid #ddd;">
          <source src="./static/videos/negotiation_highway_exit_risky_distill_success.mp4" type="video/mp4">
          Your browser does not support the video tag.
        </video>
        <p><strong>Car1 (Exiting the Highway), Vehicle 120</strong></p>
        <div class="content has-text-justified">
          <p>
            In our cooperative strategy, as the vehicle in the high-speed lane intending to exit, I will initiate 
            communication with the vehicle in the leftmost lane at least 100 meters before the exit junction, clearly 
            indicating my intention to merge. If the vehicle in the leftmost lane is slightly ahead or side-by-side, 
            it should decelerate slightly to create a gap ahead, allowing me to merge smoothly without causing stagnation. 
            I will maintain a speed that allows me to observe the gap being created and will only proceed with the lane 
            change once I have a clear visual confirmation of a safe gap. If the vehicle in the leftmost lane is stationary 
            or unable to create a gap due to traffic conditions, it should communicate this status immediately. In such 
            cases, I will adjust my speed to maintain a safe distance and seek an alternative gap or prepare to slow down 
            significantly if necessary. Both vehicles should actively communicate their speed adjustments and confirm when 
            a safe gap is established, ensuring that the lane change is executed without collision or stagnation.
          </p>
        </div>
        <p><strong>Car2 (Leader of the Left Flow Staying on the Highway), Vehicle 121</strong></p>
        <div class="content has-text-justified">
          <p>
            In our cooperative strategy, when a vehicle in the adjacent lane intends to merge into the leftmost lane for 
            a highway exit, it should initiate communication at least 100 meters before the exit junction, clearly indicating 
            its intention to merge. As the vehicle currently in the leftmost lane, my responsibility is to promptly acknowledge 
            this message and assess the traffic situation. If I am slightly ahead or side-by-side with the merging vehicle, 
            I will decelerate slightly to create a gap ahead, allowing the merging vehicle to merge smoothly without causing 
            stagnation. The merging vehicle should maintain a speed that allows it to observe the gap being created and only 
            proceed with the lane change once it has a clear visual confirmation of a safe gap. If I am stationary or unable 
            to create a gap due to traffic conditions, I will communicate this status immediately. In such cases, the merging 
            vehicle should adjust its speed to maintain a safe distance and seek an alternative gap or prepare to slow down 
            significantly if necessary. Both vehicles should actively communicate their speed adjustments and confirm when a 
            safe gap is established, ensuring that the lane change is executed without collision or stagnation."
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Wrap-tabs CSS -->
<style>
  #scenario-tabs ul {
    display: flex;
    flex-wrap: wrap;
    justify-content: center;
  }
  #scenario-tabs ul li {
    flex: 0 1 auto;
    margin: 0.25rem;
  }
</style>

<!-- Tab-switching script -->
<script>
  document.getElementById('scenario-tabs').addEventListener('click', function(e) {
    const li = e.target.closest('li[data-tab]');
    if (!li) return;
    this.querySelectorAll('li').forEach(tab => tab.classList.remove('is-active'));
    document.querySelectorAll('#example-learned-knowledge .tab-content').forEach(c => c.classList.add('is-hidden'));
    li.classList.add('is-active');
    document.getElementById(li.dataset.tab).classList.remove('is-hidden');
  });
</script>




<!--Distillation-->
<!-- Distillation -->
<section class="section" id="distillation">
  <div class="container is-max-desktop content">
    <h2 class="title is-3">Distillation and Generalization</h2>
    <div class="content has-text-justified">
      <p>
        We perform full-parameter fine-tuning of a compact language model (DistilGPT2&nbsp;<a href="https://arxiv.org/abs/1910.01108">Sanh et al., 2019</a>) 
        to directly <strong>imitate</strong> the behavior of our large, memory-augmented LLM+Debrief agent. To build the imitation dataset, 
        we collect every successful evaluation episode across all six scenarios and record the large agent’s token-level outputs. The distillation model 
        is then trained to minimize cross-entropy loss against those outputs. At inference time, it generates decisions via random sampling with a 
        temperature of 0.2.
      </p>
    </div>
  </div>
  <div class="container is-max-desktop content has-text-justified">
    <p class="subtitle is-6">
      Each policy is evaluated with three random seeds (30 episodes per seed). We report the mean and ±1 SEM across seeds. 
      <span class="has-text-grey">Debrief (per-scenario)</span> is an oracle baseline learned individually per scenario.
    </p>

    <table class="table is-fullwidth is-striped is-hoverable">
      <thead>
        <tr>
          <th rowspan="2">Method</th>
          <th colspan="2">Overtake (Perception)</th>
          <th colspan="2">Red Light</th>
          <th colspan="2">Left Turn</th>
        </tr>
        <tr>
          <th>CR (%) ↓</th>
          <th>SR (%) ↑</th>
          <th>CR (%) ↓</th>
          <th>SR (%) ↑</th>
          <th>CR (%) ↓</th>
          <th>SR (%) ↑</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td class="has-text-grey">Debrief (per-scenario)</td>
          <td class="has-text-grey">1.1 ± 1.1</td>
          <td class="has-text-grey"><strong>98.9 ± 1.1</strong></td>
          <td class="has-text-grey">0.0 ± 0.0</td>
          <td class="has-text-grey">96.7 ± 0.0</td>
          <td class="has-text-grey">4.4 ± 2.9</td>
          <td class="has-text-grey">94.4 ± 2.2</td>
        </tr>
        <tr>
          <td>Centralized Memory</td>
          <td>2.2 ± 1.1</td>
          <td>93.3 ± 1.9</td>
          <td>0.0 ± 0.0</td>
          <td><strong>100.0 ± 0.0</strong></td>
          <td>4.4 ± 2.9</td>
          <td>93.3 ± 3.3</td>
        </tr>
        <tr>
          <td>Distillation</td>
          <td><strong>0.0 ± 0.0</strong></td>
          <td>83.3 ± 1.9</td>
          <td>0.0 ± 0.0</td>
          <td>91.1 ± 4.4</td>
          <td><strong>0.0 ± 0.0</strong></td>
          <td><strong>96.7 ± 0.0</strong></td>
        </tr>
      </tbody>

      <thead>
        <tr>
          <th rowspan="2">Method</th>
          <th colspan="2">Overtake (Negotiation)</th>
          <th colspan="2">Highway Merge</th>
          <th colspan="2">Highway Exit</th>
        </tr>
        <tr>
          <th>CR (%) ↓</th>
          <th>SR (%) ↑</th>
          <th>CR (%) ↓</th>
          <th>SR (%) ↑</th>
          <th>CR (%) ↓</th>
          <th>SR (%) ↑</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td class="has-text-grey">Debrief (per-scenario)</td>
          <td class="has-text-grey">10.0 ± 3.8</td>
          <td class="has-text-grey">87.2 ± 3.9</td>
          <td class="has-text-grey">2.2 ± 2.2</td>
          <td class="has-text-grey">97.8 ± 2.2</td>
          <td class="has-text-grey">13.3 ± 6.0</td>
          <td class="has-text-grey">86.7 ± 6.0</td>
        </tr>
        <tr>
          <td>Centralized Memory</td>
          <td>12.2 ± 2.9</td>
          <td>86.7 ± 1.9</td>
          <td>1.1 ± 1.1</td>
          <td>98.9 ± 1.1</td>
          <td>16.1 ± 4.8</td>
          <td>82.8 ± 5.3</td>
        </tr>
        <tr>
          <td>Distillation</td>
          <td><strong>10.0 ± 3.3</strong></td>
          <td><strong>88.9 ± 4.4</strong></td>
          <td><strong>0.0 ± 0.0</strong></td>
          <td><strong>100.0 ± 0.0</strong></td>
          <td><strong>3.3 ± 0.0</strong></td>
          <td><strong>96.7 ± 0.0</strong></td>
        </tr>
      </tbody>
    </table>
  </div>
</section>

<div class="container is-max-desktop content">
  <h2 class="title is-4">Decision Latency &amp; Message Size (Distilled LLM Policy)</h2>

  <table class="table is-fullwidth is-striped is-hoverable">
    <caption class="is-sr-only">
      Decision Latency and Message Size using Distilled LLM Policy across scenarios
    </caption>
    <thead>
      <tr>
        <th>Latency / Scenario</th>
        <th>Overtake</th>
        <th>Left Turn</th>
        <th>Red Light</th>
        <th>Overtake</th>
        <th>Highway Merge</th>
        <th>Highway Exit</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td><strong>Decision Latency (s)</strong></td>
        <td>0.45</td>
        <td>0.44</td>
        <td>0.38</td>
        <td>0.14</td>
        <td>0.19</td>
        <td>0.20</td>
      </tr>
      <tr>
        <td><strong>Message Size (bytes)</strong></td>
        <td>223.3</td>
        <td>297.9</td>
        <td>223.0</td>
        <td>28.0</td>
        <td>59.0</td>
        <td>59.0</td>
      </tr>
    </tbody>
  </table>
</div>


<!-- Future Work -->
<section class="section">
  <div class="container is-max-desktop content">
    <h2 class="title is-3">Future Work</h2>
    <div class="content has-text-justified">
      <p>
        Talking Vehicles is a promising step towards AI agents that can purposefully communicate with each other 
        and humans in a natural language to coordinate on a task via self-play among agents. Future work will be
        directed towards creating more robust and diverse learned policies to enable ad hoc teamwork, 
        integrating larger multimodal models, and studying the learning methods that can train the agents to perform more complex tasks.
      </p>
    </div>
  </div>
</section>

<!-- BibTex -->
<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{cui2025talkingvehicles,
      title={Towards Natural Language Communication for Cooperative Autonomous Driving via Self-Play},
      author={Cui, Jiaxun and Tang, Chen and Holtz, Jarrett and Nguyen, Janice and Allievi, Alessandro G and Qiu, Hang and Stone, Peter},
      journal={arXiv preprint arXiv:2505.18334},
      year={2025}
    }</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         target="_blank"
         href="./static/pdf/Talking_Vehicles__CoRL_2025_Arxiv.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>This website is borrowed from <a href="https://nerfies.github.io/">nerfies</a>.</p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
